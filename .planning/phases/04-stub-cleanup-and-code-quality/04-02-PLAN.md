---
phase: 04-stub-cleanup-and-code-quality
plan: 02
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - veritas/agents/judge.py
  - veritas/analysis/dom_analyzer.py
  - veritas/config/dark_patterns.py
autonomous: true
requirements:
  - CORE-04
  - CORE-04-3
  - CORE-04-4
  - CORE-04-5
  - CORE-06-4

must_haves:
  truths:
    - "_summarize_dark_patterns() raises RuntimeError when vision_result is missing"
    - "_summarize_entity_verification() raises RuntimeError when graph_result is missing"
    - "_check_dark_patterns_css() raises NotImplementedError for placeholder implementation"
    - "get_prompts_for_category() raises ValueError for invalid category_id"
  artifacts:
    - path: "veritas/agents/judge.py"
      provides: "JudgeAgent with state-dependent error handling"
      min_lines: 40
      contains:
        - "_summarize_dark_patterns"
        - "_summarize_entity_verification"
        - "raise RuntimeError"
    - path: "veritas/analysis/dom_analyzer.py"
      provides: "DOMAnalyzer with stub identification"
      min_lines: 10
      contains:
        - "_check_dark_patterns_css"
        - "raise NotImplementedError"
    - path: "veritas/config/dark_patterns.py"
      provides: "Dark patterns config with input validation"
      min_lines: 8
      contains:
        - "get_prompts_for_category"
        - "raise ValueError"
  key_links:
    - from: "veritas/agents/judge.py:_summarize_dark_patterns"
      to: "evidence.vision_result"
      via: "null check"
      pattern: "if not evidence.vision_result"
    - from: "veritas/agents/judge.py:_summarize_entity_verification"
      to: "evidence.graph_result"
      via: "null check"
      pattern: "if not evidence.graph_result"
    - from: "veritas/config/dark_patterns.py:get_prompts_for_category"
      to: "DARK_PATTERN_TAXONOMY"
      via: "category lookup"
      pattern: "DARK_PATTERN_TAXONOMY.get(category_id)"
---

<objective>
Replace empty return stubs in judge.py, dom_analyzer.py, and dark_patterns.py with context-specific exceptions to eliminate silent failures and complete stub implementations.

Purpose: Empty returns mask missing state issues (judge.py) and incomplete implementations (dom_analyzer.py, dark_patterns.py). Raising exceptions makes these failures explicit.

Output: judge.py, dom_analyzer.py, dark_patterns.py with proper error handling at lines 943, 960, 345, 407.
</objective>

<execution_context>
@C:/Users/hp/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/hp/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-CONTEXT.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-RESEARCH.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-01-SUMMARY.md
@veritas/agents/judge.py
@veritas/analysis/dom_analyzer.py
@veritas/config/dark_patterns.py
</context>

<tasks>

<task type="auto">
  <name>Task 0: Search for existing callers of stub methods</name>
  <files>veritas/agents/judge.py</files>
  <action>
Before modifying stub methods, search for existing callers in the codebase using grep patterns. This is required per migration decision in 04-CONTEXT.md.

Search for all calls to the following methods:
- _summarize_dark_patterns()
- _summarize_entity_verification()
- _check_dark_patterns_css()
- get_prompts_for_category()

Use grep patterns:
```bash
grep -rn "_summarize_dark_patterns(" veritas/ --include="*.py"
grep -rn "_summarize_entity_verification(" veritas/ --include="*.py"
grep -rn "_check_dark_patterns_css(" veritas/ --include="*.py"
grep -rn "get_prompts_for_category(" veritas/ --include="*.py"
```

Analyze results:
1. If callers found, document:
   - Which methods are called
   - Where they are called (file:line)
   - How callers handle return values
2. If no callers found, report this as confirmation that stub replacement is safe
3. If callers exist and expect empty returns, evaluate whether to:
   - Update callers first (preferred migration path)
   - Implement the full method now (if feasible)

Return analysis summary before proceeding with Task 1 stub replacement.
  </action>
  <verify>grep -rn "_summarize_dark_patterns(" veritas/ --include="*.py" && grep -rn "_summarize_entity_verification(" veritas/ --include="*.py" && grep -rn "_check_dark_patterns_css(" veritas/ --include="*.py" && grep -rn "get_prompts_for_category(" veritas/ --include="*.py"</verify>
  <done>Caller analysis complete with documented findings on method usage patterns</done>
</task>

<task type="auto">
  <name>Task 1: Replace judge.py stubs with RuntimeError for missing state</name>
  <files>veritas/agents/judge.py</files>
  <action>
Modify veritas/agents/judge.py to replace empty returns with RuntimeError:

1. Line ~943 (_summarize_dark_patterns method):
   - Replace `return []` when `not evidence.vision_result`
   - Raise RuntimeError: "_summarize_dark_patterns(): Cannot summarize dark patterns without vision_result. Ensure visual analysis completed before summarization."

2. Line ~960 (_summarize_entity_verification method):
   - Replace `return []` when `not evidence.graph_result`
   - Raise RuntimeError: "_summarize_entity_verification(): Cannot summarize entity verification without graph_result. Ensure graph investigation completed before summarization."

Use RuntimeError for missing dependencies (state issues) per research guidance.

Note: Line ~318 in dom_analyzer.py (_check_excessive_tracking) returns [] for valid edge case (tracking count <= 5) - do NOT modify as this is intentional behavior, not a stub.
  </action>
  <verify>grep -n "def _summarize" veritas/agents/judge.py</verify>
  <done>All judge.py stubs (lines 943, 960) raise RuntimeError instead of returning empty lists</done>
</task>

<task type="auto">
  <name>Task 2: Replace dom_analyzer.py placeholder with NotImplementedError</name>
  <files>veritas/analysis/dom_analyzer.py</files>
  <action>
Modify veritas/analysis/dom_analyzer.py to identify incomplete implementation:

Line ~345 (_check_dark_patterns_css method):
- Replace `return []` (placeholder comment: "Additional CSS-based dark pattern checks")
- Raise NotImplementedError: "_check_dark_patterns_css(): Additional CSS-based dark pattern checks not yet implemented. This method is a placeholder for future structural checks."

Use NotImplementedError for incomplete features per research guidance.

Note: Line ~318 (_check_excessive_tracking) returns [] for valid edge case (tracking count <= 5) - do NOT modify as this is intentional behavior, not a stub.
  </action>
  <verify>grep -n "_check_dark_patterns_css" veritas/analysis/dom_analyzer.py</verify>
  <done>dom_analyzer.py stub (line 345) raises NotImplementedError for placeholder implementation</done>
</task>

<task type="auto">
  <name>Task 3: Replace dark_patterns.py stub with ValueError for invalid input</name>
  <files>veritas/config/dark_patterns.py</files>
  <action>
Modify veritas/config/dark_patterns.py to validate input:

Line ~407 (get_prompts_for_category function):
- Replace `return []` when `category = DARK_PATTERN_TAXONOMY.get(category_id)` is None
- Raise ValueError: f"get_prompts_for_category(): Invalid category_id '{category_id}'. Valid categories: {list(DARK_PATTERN_TAXONOMY.keys())}"

Use ValueError for invalid input/input validation errors per research guidance.
  </action>
  <verify>grep -n "def get_prompts_for_category" veritas/config/dark_patterns.py</verify>
  <done>dark_patterns.py stub (line 407) raises ValueError for invalid category_id</done>
</task>

</tasks>

<verification>
1. Verify _summarize_dark_patterns raises RuntimeError when vision_result is None
2. Verify _summarize_entity_verification raises RuntimeError when graph_result is None
3. Verify _check_dark_patterns_css raises NotImplementedError for placeholder
4. Verify get_prompts_for_category raises ValueError for invalid category_id
5. Verify _check_excessive_tracking still returns [] for acceptable tracking levels (not modified)
6. No empty return statements at lines 943, 960, 345, 407
</verification>

<success_criteria>
1. All specified stub replacements complete in judge.py, dom_analyzer.py, dark_patterns.py
2. Error messages include method name and context for debugging
3. Valid empty returns preserved (dom_analyzer.py line 318 for acceptable tracking)
4. Code follows patterns from 04-RESEARCH.md (RuntimeError for state issues, NotImplementedError for incomplete features, ValueError for invalid input)
</success_criteria>

<output>
After completion, create `.planning/phases/04-stub-cleanup-and-code-quality/04-02-SUMMARY.md`
</output>
