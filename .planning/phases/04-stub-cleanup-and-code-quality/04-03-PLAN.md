---
phase: 04-stub-cleanup-and-code-quality
plan: 03
type: execute
wave: 3
depends_on: [04-01, 04-02]
files_modified:
  - veritas/tests/test_stub_cleanup.py
autonomous: true
requirements:
  - CORE-04
  - CORE-04-2
  - CORE-04-3
  - CORE-04-4
  - CORE-04-5
  - CORE-06-4

must_haves:
  truths:
    - "All exception scenarios from Plans 01 and 02 have corresponding pytest.raises() tests"
    - "Running pytest for stub cleanup tests passes with all tests green"
    - "Tests use pytest.raises() context manager per research pattern"
    - "Test file follows project pattern (test_ipc_queue.py, test_security_agent.py)"
  artifacts:
    - path: "veritas/tests/test_stub_cleanup.py"
      provides: "Comprehensive test coverage for stub cleanup exceptions"
      min_lines: 200
      contains:
        - "import pytest"
        - "with pytest.raises"
        - "class TestEvidenceStoreStubs"
        - "class TestJudgeStubs"
        - "class TestDOMAnalyzerStubs"
        - "class TestDarkPatternsStubs"
  key_links:
    - from: "veritas/tests/test_stub_cleanup.py"
      to: "veritas/core/evidence_store.py"
      via: "import statements"
      pattern: "from core.evidence_store import EvidenceStore"
    - from: "veritas/tests/test_stub_cleanup.py"
      to: "veritas/agents/judge.py"
      via: "import statements"
      pattern: "from agents.judge import JudgeAgent"
    - from: "veritas/tests/test_stub_cleanup.py"
      to: "veritas/analysis/dom_analyzer.py"
      via: "import statements"
      pattern: "from analysis.dom_analyzer import DOMAnalyzer"
    - from: "veritas/tests/test_stub_cleanup.py"
      to: "veritas/config/dark_patterns.py"
      via: "import statements"
      pattern: "from config.dark_patterns import get_prompts_for_category"
---

<objective>
Create comprehensive test suite for stub cleanup exceptions to verify NotImplementedError, ValueError, and RuntimeError are raised as expected.

Purpose: Tests prevent regression and verify that stub replacements work correctly. Uses pytest.raises() pattern established in test_ipc_queue.py and test_security_dataclasses.py.

Output: New test file veritas/tests/test_stub_cleanup.py with 10+ exception tests.
</objective>

<execution_context>
@C:/Users/hp/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/hp/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-CONTEXT.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-RESEARCH.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-01-SUMMARY.md
@.planning/phases/04-stub-cleanup-and-code-quality/04-02-SUMMARY.md
@veritas/tests/test_ipc_queue.py
@veritas/tests/test_security_dataclasses.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create test_stub_cleanup.py with exception tests</name>
  <files>veritas/tests/test_stub_cleanup.py</files>
  <action>
Create new test file veritas/tests/test_stub_cleanup.py following project patterns from test_ipc_queue.py and test_security_dataclasses.py.

Imports:
```python
import pytest
from core.evidence_store import EvidenceStore
from agents.judge import JudgeAgent
from analysis.dom_analyzer import DOMAnalyzer
from config.dark_patterns import get_prompts_for_category, DARK_PATTERN_TAXONOMY
from dataclasses import dataclass
```

Class structure with tests:

1. TestEvidenceStoreStubs:
   - test_search_similar_table_not_exists (ValueError) - mock LanceDB with missing table
   - test_get_all_audits_table_not_exists (ValueError) - mock LanceDB with missing audits table
   - test_json_search_file_not_exists (FileNotFoundError) - test _json_search with missing file
   - test_json_search_exception (RuntimeError) - test _json_search with invalid JSON
   - test_json_list_all_file_not_exists (FileNotFoundError) - test _json_list_all with missing file
   - test_json_list_all_exception (RuntimeError) - test _json_list_all with invalid JSON

2. TestJudgeStubs:
   - test_summarize_dark_patterns_no_vision_result (RuntimeError) - mock AuditEvidence with vision_result=None
   - test_summarize_entity_verification_no_graph_result (RuntimeError) - mock AuditEvidence with graph_result=None

3. TestDOMAnalyzerStubs:
   - test_check_dark_patterns_css_not_implemented (NotImplementedError) - call method directly

4. TestDarkPatternsStubs:
   - test_get_prompts_for_category_invalid_id (ValueError) - pass invalid category_id
   - test_get_prompts_for_category_valid_id_passes (verification) - pass valid category_id and verify prompts returned

Use pytest.raises() context manager pattern from existing test files (see test_security_dataclasses.py:187, test_ipc_queue.py:134).

Use mocking where needed to trigger exception conditions without external dependencies.
  </action>
  <verify>python -m pytest veritas/tests/test_stub_cleanup.py -v</verify>
  <done>test_stub_cleanup.py created with all exception tests passing</done>
</task>

</tasks>

<verification>
1. Test file exists at veritas/tests/test_stub_cleanup.py
2. pytest.raises() used for all exception tests (per research pattern)
3. All 10+ tests pass: pytest veritas/tests/test_stub_cleanup.py -v
4. Test coverage includes all stub locations from Plans 01 and 02
5. Tests follow project patterns (test_ipc_queue.py structure)
6. Documentation strings explain what each test verifies
</verification>

<success_criteria>
1. test_stub_cleanup.py created with comprehensive exception tests
2. All tests pass (pytest.raises() pattern verified)
3. Tests cover CORE-06-4 requirement (stub cleanup verified by tests)
4. Test file follows project conventions and patterns
5. Overall test suite passes: pytest veritas/tests/ -v (all existing + new tests)
</success_criteria>

<output>
After completion, create `.planning/phases/04-stub-cleanup-and-code-quality/04-03-SUMMARY.md`
</output>
