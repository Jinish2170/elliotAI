---
phase: 01-ipc-communication-stabilization
plan: 04
type: execute
wave: 3
depends_on:
  - 01-03
files_modified:
  - backend/services/audit_runner.py
  - backend/__init__.py
autonomous: true
requirements:
  - CORE-02
  - CORE-02-4
  - CORE-02-5

must_haves:
  truths:
    - AuditRunner creates Queue when Queue mode is selected
    - subprocess receives Queue via environment variables
    - Queue reader task runs in background and sends events to WebSocket
    - Auto-fallback to stdout on Queue failures
    - --use-queue-ipc flag added to subprocess command
  artifacts:
    - path: backend/services/audit_runner.py
      contains: _determine_ipc_mode method
      contains: _run_with_queue method
      contains: _read_queue_and_stream method
    - path: backend/__init__.py
      contains: spawn context configuration (Windows compatibility)
  key_links:
    - from: backend/services/audit_runner.py
      to: veritas/core/ipc.py
      via: import statements
      pattern: from veritas\.core\.ipc import
    - from: backend/services/audit_runner.py
      to: subprocess environment
      via: env["AUDIT_QUEUE_*"] variables
      pattern: env\["AUDIT_QUEUE_(KEY|FD)"
    - from: backend/services/audit_runner.py
      to: progress_queue
      via: Queue.get() in asyncio.to_thread()
      pattern: await asyncio\.to_thread\(self\.progress_queue\.get

---

<objective>
Modify AuditRunner to create Queue for subprocess communication and implement auto-fallback to stdout mode on Queue failures.

Purpose: Enable backend to use Queue IPC with real-time progress streaming while maintaining instant rollback to stdout parsing.

Output: Modified `backend/services/audit_runner.py` with Queue creation, subprocess environment setup, and auto-fallback logic.
</objective>

<execution_context>
@C:/Users/hp/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/hp/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-ipc-communication-stabilization/01-CONTEXT.md
@.planning/phases/01-ipc-communication-stabilization/01-RESEARCH.md
@.planning/STATE.md
@.planning/ROADMAP.md

# Codebase references
@C:/files/coding dev era/elliot/elliotAI/backend/services/audit_runner.py
@C:/files/coding dev era/elliot/elliotAI/veritas/core/ipc.py (created in Plan 01)
@C:/files/coding dev era/elliot/elliotAI/veritas/core/orchestrator.py (modified in Plan 03)

# Prior plans
@.planning/phases/01-ipc-communication-stabilization/01-01-SUMMARY.md (not yet created)
@.planning/phases/01-ipc-communication-stabilization/01-02-SUMMARY.md (not yet created)
@.planning/phases/01-ipc-communication-stabilization/01-03-SUMMARY.md (not yet created)
</context>

<tasks>

<task type="auto">
  <name>Configure spawn context in backend/__init__.py</name>
  <files>backend/__init__.py</files>
  <action>
    Create or modify `backend/__init__.py` to set spawn context:

    1. Create file if it doesn't exist, or edit existing file

    2. Add multiprocessing spawn context setup at module level:
    ```python
    """Backend package for Veritas FastAPI server."""

    import sys
    import multiprocessing

    # Set spawn context ONCE at module import time (required for Windows)
    if sys.platform == "win32":
        multiprocessing.set_start_method('spawn', force=True)
    ```

    3. This ensures consistent spawn context across backend module imports

    4. Add docstring explaining Windows spawn context requirement

    DO NOT import any other modules here - keep it minimal to avoid import issues.
  </action>
  <verify>
    python -c "import sys; sys.path.insert(0, 'C:/files/coding dev era/elliot/elliotAI'); from backend import multiprocess; print('OK')" 2>&1 || python -c "import sys; import os; os.chdir('C:/files/coding dev era/elliot/elliotAI'); exec(open('backend/__init__.py').read()); print('OK')"
  </verify>
  <done>
    backend/__init__.py sets multiprocessing spawn context for Windows compatibility without import errors.
  </done>
</task>

<task type="auto">
  <name>Add IPC mode determination and Queue creation to AuditRunner</name>
  <files>backend/services/audit_runner.py</files>
  <action>
    Modify `backend/services/audit_runner.py` with Queue support:

    1. Add imports at top (after existing imports):
    ```python
    import multiprocessing as mp
    import queue  # For queue.Empty exception
    from typing import Optional

    # Import IPC utilities - may need to adjust path based on project structure
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent / "veritas"))
    from core.ipc import determine_ipc_mode, IPC_MODE_QUEUE, create_queue, serialize_queue
    ```

    2. Add to `AuditRunner.__init__` after line 56:
    ```python
    # Determine IPC mode (CLI args would be set externally, for now use env/default)
    self.ipc_mode = self._determine_ipc_mode()
    self.progress_queue: Optional[mp.Queue] = None
    self._mgr = None
    ```

    3. Add `_determine_ipc_mode(self) -> str` method (after __init__):
    ```python
    def _determine_ipc_mode(self) -> str:
        """Determine IPC mode from environment or use percentage-based default."""
        # For now, use environment variables only (CLI flags would come from API request)
        ipc_mode = determine_ipc_mode(cli_use_queue_ipc=False, cli_use_stdout=False)
        return ipc_mode
    ```

    4. In `async def run(self, send: Callable)` after lines 72-81 (cmd construction), add Queue setup:
    ```python
    # Setup Queue if Queue mode selected
    self.progress_queue = None
    self._mgr = None
    queue_env_vars = {}

    if self.ipc_mode == IPC_MODE_QUEUE:
        try:
            mp.set_start_method('spawn', force=True)
            self._mgr = mp.Manager()
            self.progress_queue = self._mgr.Queue(maxsize=1000)
            fd, serialized = serialize_queue(self.progress_queue)
            queue_env_vars = {
                "AUDIT_QUEUE_FD": str(fd),
                "AUDIT_QUEUE_KEY": serialized,
            }
            cmd.append("--use-queue-ipc")  # Pass flag to subprocess
            logger.info(f"[{self.audit_id}] Using Queue IPC mode")
        except Exception as e:
            logger.warning(f"[{self.audit_id}] Queue creation failed: {e}, falling back to stdout mode")
            self.ipc_mode = "stdout"
    else:
        logger.info(f"[{self.audit_id}] Using stdout IPC mode")
    ```

    5. Merge queue_env_vars into env dict: `env = {**os.environ, **env_vars}`

    DO NOT modify existing subprocess.Popen call or stdout parsing yet - those are next.
  </action>
  <verify>
    python -c "
import sys
sys.path.insert(0, 'C:/files/coding dev era/elliot/elliotAI/backend')
from services.audit_runner import AuditRunner
runner = AuditRunner('test', 'https://example.com', 'quick_scan')
assert runner.ipc_mode in ['queue', 'stdout']
print('OK - IPC mode determined')
"
  </verify>
  <done>
    AuditRunner determines IPC mode, creates Queue when Queue mode selected, sets environment variables for subprocess.
  </done>
</task>

<task type="auto">
  <name>Implement Queue reader and auto-fallback in AuditRunner</name>
  <files>backend/services/audit_runner.py</files>
  <action>
    Modify `backend/services/audit_runner.py` to add Queue reader and fallback:

    1. Add `_run_with_queue(self, send: Callable)` method (before existing _handle_progress):
    ```python
    async def _run_with_queue(self, send: Callable):
        """Run subprocess with Queue IPC and fallback to stdout on failure."""
        loop = asyncio.get_running_loop()

        # Read queue in background task
        read_task = asyncio.create_task(self._read_queue_and_stream(send))

        try:
            # Start subprocess (existing code from run() method)
            # [Reuse the existing subprocess.Popen and stdout parsing code here]

            # Wait for process to finish
            await loop.run_in_executor(None, process.wait)

            # Stop queue reader
            read_task.cancel()
            try:
                await asyncio.wait_for(read_task, timeout=5)
            except Exception:
                pass

        except (pickle.PickleError, mp.ProcessError, queue.Empty) as e:
            logger.warning(f"[{self.audit_id}] Queue IPC failed: {e}, falling back to stdout mode")
            read_task.cancel()
            # Cleanup Queue
            if self._mgr:
                self._mgr.shutdown()
            # Rerun with stdout mode
            return await self._run_with_stdout(send)

        finally:
            # Cleanup Manager
            if self._mgr:
                self._mgr.shutdown()

        # Ensure completion event
        [existing completion code]
    ```

    2. Add `_read_queue_and_stream(self, send: Callable)` method:
    ```python
    async def _read_queue_and_stream(self, send: Callable):
        """Read events from Queue and send to WebSocket."""
        loop = asyncio.get_running_loop()
        if self.progress_queue is None:
            return

        while True:
            try:
                # Non-blocking get with 1 second timeout
                event = await asyncio.to_thread(self.progress_queue.get, timeout=1.0)

                # Convert ProgressEvent dataclass to dict if needed
                if hasattr(event, '__dict__'):
                    event_dict = {
                        "type": getattr(event, 'type', 'progress'),
                        "phase": getattr(event, 'phase', ''),
                        "step": getattr(event, 'step', ''),
                        "pct": getattr(event, 'pct', 0),
                        "detail": getattr(event, 'detail', ''),
                        "summary": getattr(event, 'summary', {}) or {},
                    }
                    # Handle phase_start mapping
                    if event_dict["step"] in ("navigating", "scanning", "analyzing", "investigating", "deliberating"):
                        await send({
                            "type": "phase_start",
                            "phase": event_dict["phase"],
                            "message": event_dict["detail"],
                            "pct": event_dict["pct"],
                        })
                    # Handle phase_complete mapping
                    elif event_dict["step"] == "done":
                        await send({
                            "type": "phase_complete",
                            "phase": event_dict["phase"],
                            "message": event_dict["detail"],
                            "pct": event_dict["pct"],
                            "summary": event_dict["summary"],
                        })
                    elif event_dict["step"] == "error":
                        await send({
                            "type": "phase_error",
                            "phase": event_dict["phase"],
                            "message": event_dict["detail"],
                        })
                else:
                    # Already a dict
                    await send(event)

            except queue.Empty:
                continue  # No events yet, poll again
            except asyncio.CancelledError:
                logger.info(f"[{self.audit_id}] Queue reader cancelled")
                break
            except Exception as e:
                logger.error(f"[{self.audit_id}] Queue read error: {e}")
                continue
    ```

    3. Refactor existing `run()` method to extract subprocess code and call appropriate method:
    - Extract subprocess setup (lines 69-100) into common code
    - Call `_run_with_queue(send)` if Queue mode
    - Otherwise run existing stdout parsing code (rename to `_run_with_stdout(send)`)

    4. Keep existing stdout parsing logic intact for fallback

    DO NOT remove existing _handle_progress and _handle_result methods - keep them for both modes.
  </action>
  <verify>
    python -c "
# Test that _read_queue_and_stream can be created and has async signature
import inspect, sys
sys.path.insert(0, 'C:/files/coding dev era/elliot/elliotAI/backend')
from services.audit_runner import AuditRunner
runner = AuditRunner('test', 'https://example.com', 'quick_scan')
method = getattr(runner, '_read_queue_and_stream', None)
assert method is not None, 'Method exists'
assert inspect.iscoroutinefunction(method), 'Method is async'
print('OK - Queue reader method exists')
"
  </verify>
  <done>
    AuditRunner has _run_with_queue method, _read_queue_and_stream method with async Queue reading, and auto-fallback to stdout on Queue failures.
  </done>
</task>

</tasks>

<verification>
1. multiprocessing spawn context configured in backend/__init__.py
2. AuditRunner determines IPC mode from environment
3. Queue is created, serialized, and passed to subprocess via environment
4. _read_queue_and_stream reads events from Queue and sends to WebSocket
5. Queue failures trigger auto-fallback to stdout mode
6. Existing stdout parsing preserved for backward compatibility
</verification>

<success_criteria>
1. Backend uses multiprocessing.Queue when Queue mode selected
2. Queue passes to subprocess via environment variables
3. Queue reader task runs in background process
4. Auto-fallback to stdout on Queue creation or communication failures
5. No regression in existing stdout-based audits
</success_criteria>

<output>
After completion, create `.planning/phases/01-ipc-communication-stabilization/01-04-SUMMARY.md`
</output>
